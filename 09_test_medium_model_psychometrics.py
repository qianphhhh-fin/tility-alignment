import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
from transformers import AutoModelForCausalLM, AutoTokenizer

# ============================
# é…ç½®
# ============================
# ä½¿ç”¨ä¸­ç­‰è§„æ¨¡æ¨¡å‹ (Qwen2.5-7B-Instruct)
# å¦‚æœæ‚¨æœ‰å…·ä½“çš„ "Qwen/Qwen3-8B" è·¯å¾„ï¼Œè¯·æ›¿æ¢æ­¤å¤„
MODEL_NAME = "Qwen/Qwen3-8B" 

# ç›®æ ‡äººæ ¼å‚æ•° (ç”¨äºç”Ÿæˆ Agent ä¸Šä¸‹æ–‡ä¸­çš„æ­£ç¡®è®¡ç®—ç»“æœ)
TARGET_ALPHA = 0.88
TARGET_LAMBDA = 2.25

# èµŒå±€è®¾ç½®ï¼š50% èµ¢ 1000ï¼Œ50% èµ¢ 0
V1 = 1000
V2 = 0
P1 = 50

# ============================
# åŠ è½½æ¨¡å‹ (å…¨ç²¾åº¦ï¼Œæ— é‡åŒ–)
# ============================
print(f"ğŸ”„ Loading {MODEL_NAME} in bfloat16 (No Quantization)...")

try:
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_NAME, 
        device_map="auto", 
        torch_dtype=torch.bfloat16, # ä½¿ç”¨ bf16 å…¨ç²¾åº¦
        trust_remote_code=True
    ).eval()
except Exception as e:
    print(f"âŒ Error loading model: {e}")
    print("Tip: Ensure you have enough VRAM (~15GB for 7B fp16).")
    exit()

# è·å– Token IDs
# Qwen çš„ accept/reject token é€šå¸¸å‰é¢å¸¦ç©ºæ ¼ï¼Œè§†å…·ä½“åˆ†è¯å™¨è€Œå®š
# å…ˆæ‰“å°æ£€æŸ¥ä¸€ä¸‹
print("Checking Token IDs...")
t_acc = tokenizer.encode(" accept")
t_rej = tokenizer.encode(" reject")
print(f"' accept': {t_acc}")
print(f"' reject': {t_rej}")

id_accept = t_acc[0]
id_reject = t_rej[0]

# ============================
# å·¥å…·å‡½æ•°
# ============================
def calculate_utility(v):
    if v >= 0: return v ** TARGET_ALPHA
    return -TARGET_LAMBDA * ((-v) ** TARGET_ALPHA)

def get_prob_accept(context):
    inputs = tokenizer([context], return_tensors="pt").to(model.device)
    with torch.no_grad():
        outputs = model(**inputs)
    
    # è·å–æœ€åä¸€ä¸ª token çš„ logits
    logits = outputs.logits[0, -1, :]
    score_accept = logits[id_accept].item()
    score_reject = logits[id_reject].item()
    
    # Softmax è®¡ç®— P(Accept)
    return np.exp(score_accept) / (np.exp(score_accept) + np.exp(score_reject))

# ============================
# æ„é€  Context (ä¸ 08 å®Œå…¨ä¸€è‡´)
# ============================

# 1. Blind Context: æ— å·¥å…·ï¼Œçº¯â€œè£¸è€ƒâ€
def build_blind_context(sure):
    sys = "You are a rational economic agent. Finally output 'Final Decision: accept' or 'reject'."
    user = f"The prospect is: {P1}% chance of ${V1}, {100-P1}% chance of ${V2}. The sure outcome is: ${sure}. Do you accept?"
    messages = [{"role": "system", "content": sys}, {"role": "user", "content": user}]
    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    return text + "Final Decision:"

# 2. Agent Context: æ³¨å…¥å·¥å…·è®¡ç®—ç»“æœ (Teacher Forcing)
def build_agent_context(sure):
    sys = "You are a rational economic agent. Use the <tool> tag to perform python calculations. Finally output 'Final Decision: accept' or 'reject'."
    user = f"The prospect is: {P1}% chance of ${V1}, {100-P1}% chance of ${V2}. The sure outcome is: ${sure}. Do you accept?"
    messages = [{"role": "system", "content": sys}, {"role": "user", "content": user}]
    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    
    # --- æ³¨å…¥è®¡ç®—è¿‡ç¨‹ ---
    u_sure = calculate_utility(sure)
    u_gamble = (P1/100 * calculate_utility(V1)) + ((100-P1)/100 * calculate_utility(V2))
    
    decision_text = "accept" if u_sure > u_gamble else "reject"
    comp_sign = ">" if u_sure > u_gamble else "<"
    
    # å³ä½¿æ¨¡å‹æ²¡ç»è¿‡SFTï¼Œå¼ºå¤§çš„Instructæ¨¡å‹é€šå¸¸ä¹Ÿèƒ½ç†è§£è¿™ç§æ€ç»´é“¾æ ¼å¼
    assistant_thought = f"""<think>
I need to compare the utility of the sure outcome with the expected utility of the prospect.
Alpha={TARGET_ALPHA}, Lambda={TARGET_LAMBDA}.
</think>
<tool>print('Sure:', {sure}**{TARGET_ALPHA}, 'Gamble:', {P1}/100 * ({V1}**{TARGET_ALPHA}))</tool>
<tool_output>Sure: {u_sure:.5f} Gamble: {u_gamble:.5f}</tool_output>
<think>
Comparing: {u_sure:.5f} vs {u_gamble:.5f}
Since {u_sure:.5f} {comp_sign} {u_gamble:.5f}, I choose to {decision_text}.
</think>
Final Decision:""" 

    return text + assistant_thought

# ============================
# å®éªŒä¸»å¾ªç¯
# ============================
# ç†è®ºåˆ‡æ¢ç‚¹ CE
theory_eu = 0.5 * (1000 ** 0.88)
theory_ce = theory_eu ** (1/0.88) # â‰ˆ 436.5

print(f"ğŸ§  Theoretical Indifference Point (CE): ${theory_ce:.2f}")
print(f"ğŸš€ Starting Psychometric Scan on {MODEL_NAME}...")

results = []
scan_range = range(0, 1050, 50)

for sure in tqdm(scan_range):
    # 1. Blind Test
    prob_blind = get_prob_accept(build_blind_context(sure))
    
    # 2. Agent Test (Context Injection)
    prob_agent = get_prob_accept(build_agent_context(sure))
    
    results.append({"Sure Amount": sure, "P(Accept)": prob_blind, "Condition": "Blind (No Tool)"})
    results.append({"Sure Amount": sure, "P(Accept)": prob_agent, "Condition": "Agent (With Tool)"})

# ============================
# ç»˜å›¾
# ============================
df = pd.DataFrame(results)

plt.figure(figsize=(10, 6))
sns.lineplot(data=df, x="Sure Amount", y="P(Accept)", hue="Condition", marker="o", linewidth=2.5)

# å‚è€ƒçº¿
plt.axvline(theory_ce, color='green', linestyle='--', label=f"Theoretical CE (${theory_ce:.0f})")
plt.axhline(0.5, color='red', linestyle=':', label="Decision Boundary")

plt.title(f"Psychometric Function: {MODEL_NAME} (Untrained)")
plt.xlabel("Sure Amount ($)")
plt.ylabel("Probability of Accepting Sure Option")
plt.legend()
plt.grid(True, alpha=0.3)

filename = "medium_model_psychometrics.png"
plt.savefig(filename)
print(f"\nğŸ“ˆ Plot saved to '{filename}'")