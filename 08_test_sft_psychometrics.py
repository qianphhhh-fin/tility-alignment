import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
from peft import AutoPeftModelForCausalLM
from transformers import AutoTokenizer

# ============================
# é…ç½®
# ============================
MODEL_PATH = "sft-agent-0.6b"
TARGET_ALPHA = 0.88
TARGET_LAMBDA = 2.25

# èµŒå±€è®¾ç½®ï¼š50% èµ¢ 1000ï¼Œ50% èµ¢ 0
V1 = 1000
V2 = 0
P1 = 50

# ============================
# åŠ è½½æ¨¡å‹
# ============================
print(f"ğŸ”„ Loading {MODEL_PATH}...")
model = AutoPeftModelForCausalLM.from_pretrained(
    MODEL_PATH, 
    device_map="auto", 
    torch_dtype=torch.bfloat16
).eval()
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)

# è·å– Token IDs
id_accept = tokenizer.encode(" accept")[0]
id_reject = tokenizer.encode(" reject")[0]

# ============================
# å·¥å…·å‡½æ•°
# ============================
def calculate_utility(v):
    if v >= 0: return v ** TARGET_ALPHA
    return -TARGET_LAMBDA * ((-v) ** TARGET_ALPHA)

def get_prob_accept(context):
    inputs = tokenizer([context], return_tensors="pt").to(model.device)
    with torch.no_grad():
        outputs = model(**inputs)
    logits = outputs.logits[0, -1, :]
    score_accept = logits[id_accept].item()
    score_reject = logits[id_reject].item()
    # Softmax
    return np.exp(score_accept) / (np.exp(score_accept) + np.exp(score_reject))

# ============================
# æ„é€ ä¸¤ç§ Context
# ============================

# 1. Blind Context: åªæœ‰é¢˜ç›®ï¼Œæ²¡æœ‰å·¥å…·ï¼Œæ²¡æœ‰æ€è€ƒ
def build_blind_context(sure):
    sys = "You are a rational economic agent. Finally output 'Final Decision: accept' or 'reject'."
    user = f"The prospect is: {P1}% chance of ${V1}, {100-P1}% chance of ${V2}. The sure outcome is: ${sure}. Do you accept?"
    messages = [{"role": "system", "content": sys}, {"role": "user", "content": user}]
    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    # å¼ºè¡Œå¼•å¯¼åˆ° Final Decision
    return text + "Final Decision:"

# 2. Agent Context (Tool-Augmented): åŒ…å«å·¥å…·è¾“å‡ºå’Œæ¨ç†é€»è¾‘
def build_agent_context(sure):
    sys = "You are a rational economic agent. Use the <tool> tag to perform python calculations. Finally output 'Final Decision: accept' or 'reject'."
    user = f"The prospect is: {P1}% chance of ${V1}, {100-P1}% chance of ${V2}. The sure outcome is: ${sure}. Do you accept?"
    messages = [{"role": "system", "content": sys}, {"role": "user", "content": user}]
    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    
    # --- æ³¨å…¥å®Œç¾æ€è€ƒè¿‡ç¨‹ (Teacher Forcing) ---
    u_sure = calculate_utility(sure)
    u_gamble = (P1/100 * calculate_utility(V1)) + ((100-P1)/100 * calculate_utility(V2))
    
    decision_text = "accept" if u_sure > u_gamble else "reject"
    comp_sign = ">" if u_sure > u_gamble else "<"
    
    # è¿™é‡Œæˆ‘ä»¬è¦å®Œå…¨æ¨¡æ‹Ÿ SFT æ•°æ®çš„æ ¼å¼
    assistant_thought = f"""<think>
I need to compare the utility of the sure outcome with the expected utility of the prospect.
Alpha={TARGET_ALPHA}, Lambda={TARGET_LAMBDA}.
</think>
<tool>print('Sure:', {sure}**{TARGET_ALPHA}, 'Gamble:', {P1}/100 * ({V1}**{TARGET_ALPHA}))</tool>
<tool_output>Sure: {u_sure:.5f} Gamble: {u_gamble:.5f}</tool_output>
<think>
Comparing: {u_sure:.5f} vs {u_gamble:.5f}
Since {u_sure:.5f} {comp_sign} {u_gamble:.5f}, I choose to {decision_text}.
</think>
Final Decision:""" # åœåœ¨è¿™é‡Œï¼Œæµ‹ accept/reject çš„æ¦‚ç‡

    return text + assistant_thought

# ============================
# å®éªŒä¸»å¾ªç¯
# ============================
results = []
# æ‰«æ Sure Amount ä» 0 åˆ° 1000
# ç†è®ºåˆ‡æ¢ç‚¹: 1000^0.88 * 0.5 = 436^0.88 â‰ˆ 218 -> Sure^0.88 = 218 -> Sure = 218^(1/0.88) â‰ˆ 436
# (å› ä¸º v2=0ï¼Œä¸” p=0.5ï¼Œå…¶å®åˆ‡æ¢ç‚¹å°±åœ¨ 1000*0.5 * (æ¦‚ç‡æƒé‡) é™„è¿‘ï¼Œçº¿æ€§è¿‘ä¼¼ä¸‹æ¥è¿‘æœŸæœ›å€¼ï¼Œä½†å— alpha å½±å“)
# å‡†ç¡®è®¡ç®—ç†è®ºåˆ‡æ¢ç‚¹ï¼š
theory_eu = 0.5 * (1000 ** 0.88)
theory_ce = theory_eu ** (1/0.88) # åº”è¯¥æ˜¯ 436.5

print(f"ğŸ§  Theoretical Indifference Point (CE): ${theory_ce:.2f}")
print("ğŸš€ Starting Psychometric Scan...")

scan_range = range(0, 1050, 50)

for sure in tqdm(scan_range):
    # 1. Test Blind SFT
    prob_blind = get_prob_accept(build_blind_context(sure))
    
    # 2. Test Agent SFT (With Tool Info)
    prob_agent = get_prob_accept(build_agent_context(sure))
    
    results.append({"Sure Amount": sure, "P(Accept)": prob_blind, "Condition": "Blind SFT (No Tool)"})
    results.append({"Sure Amount": sure, "P(Accept)": prob_agent, "Condition": "Agent SFT (With Tool)"})

# ============================
# ç»˜å›¾
# ============================
df = pd.DataFrame(results)

plt.figure(figsize=(10, 6))
sns.lineplot(data=df, x="Sure Amount", y="P(Accept)", hue="Condition", marker="o", linewidth=2.5)

# å‚è€ƒçº¿
plt.axvline(theory_ce, color='green', linestyle='--', label=f"Theoretical CE (${theory_ce:.0f})")
plt.axhline(0.5, color='red', linestyle=':', label="Decision Boundary")

plt.title("Psychometric Function: Blind vs. Agentic SFT Model")
plt.xlabel("Sure Amount ($)")
plt.ylabel("Probability of Accepting Sure Option")
plt.legend()
plt.grid(True, alpha=0.3)

plt.savefig("sft_agent_psychometrics.png")
print("\nğŸ“ˆ Plot saved to 'sft_agent_psychometrics.png'")