
---

# ğŸ§  Utility Alignment: LLM Economic Rationality Experiment
# ç»æµæ•ˆç”¨å¯¹é½ï¼šåŸºäºå‰æ™¯ç†è®ºçš„ LLM Agent å®éªŒ

![Python](https://img.shields.io/badge/Python-3.10%2B-blue) ![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange) ![HuggingFace](https://img.shields.io/badge/HuggingFace-Transformers-yellow) ![License](https://img.shields.io/badge/License-MIT-green)

æœ¬é¡¹ç›®æ—¨åœ¨æ¢ç´¢å¦‚ä½•é€šè¿‡ **ç›‘ç£å¾®è°ƒ (SFT)** å’Œ **å¼ºåŒ–å­¦ä¹  (GRPO/RL)**ï¼Œå°†å¤§å‹è¯­è¨€æ¨¡å‹ (LLM) çš„å†³ç­–è¡Œä¸ºä¸ç‰¹å®šçš„ç»æµå­¦æ•ˆç”¨å‡½æ•°ï¼ˆ[å‰æ™¯ç†è®º Prospect Theory](https://en.wikipedia.org/wiki/Prospect_theory)ï¼‰è¿›è¡Œå¯¹é½ã€‚

é€šè¿‡è®©æ¨¡å‹å­¦ä¹ ä½¿ç”¨ Python å·¥å…·è®¡ç®—æ•ˆç”¨å€¼ï¼Œå¹¶ç»“åˆæ€ç»´é“¾ (CoT)ï¼Œæˆ‘ä»¬å°†ä¸€ä¸ªåŸºç¡€çš„å°å‹æ¨¡å‹ (`Qwen/Qwen3-0.6B`) è®­ç»ƒæˆäº†ä¸€ä¸ªå…·å¤‡ç‰¹å®šé£é™©åå¥½ï¼ˆ$\alpha=0.88, \lambda=2.25$ï¼‰çš„ç†æ€§ç»æµ Agentã€‚

## ğŸ¯ æ ¸å¿ƒç›®æ ‡

1.  **äººæ ¼å¯¹é½ (Alignment):** å¼ºåˆ¶æ¨¡å‹éµå¾ªç‰¹å®šçš„äººç±»ç»æµåå¥½ï¼ˆå¦‚æŸå¤±åŒæ¶ã€è¾¹é™…æ•ˆç”¨é€’å‡ï¼‰ï¼Œè€Œéä»…ä»…æ˜¯é£é™©ä¸­æ€§ (Expected Value) æˆ–é¢„è®­ç»ƒæ—¶çš„éšæœºåå¥½ã€‚
2.  **å·¥å…·å¢å¼º (Tool-Use):** è®­ç»ƒæ¨¡å‹åœ¨å†³ç­–å‰ä¸»åŠ¨è°ƒç”¨ Python è®¡ç®—å™¨ï¼Œç¡®ä¿æ•°å€¼è®¡ç®—çš„å‡†ç¡®æ€§ï¼Œé¿å…å¤§æ¨¡å‹çš„ç®—æœ¯å¹»è§‰ã€‚
3.  **å¿ƒç†æµ‹é‡ (Psychometrics):** ä½¿ç”¨å¿ƒç†ç‰©ç†å­¦æ–¹æ³•ï¼ˆPsychometric Functionsï¼‰é‡åŒ–è¯„ä¼°æ¨¡å‹çš„é£é™©åå¥½æ›²çº¿ã€‚

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

*   **Model:** Qwen/Qwen3-0.6B (SFT/RL), Qwen/Qwen3-8B (Baseline Analysis)
*   **Training:** LoRA (PEFT), SFTTrainer, GRPOTrainer (TRL)
*   **Environment:** è‡ªå®šä¹‰ `calculator_env` (Server-Client æ¶æ„)
*   **Analysis:** Pandas, Seaborn, Matplotlib

## ğŸ“¦ å®‰è£…ä¸å‡†å¤‡

### 1. ç¯å¢ƒä¾èµ–
è¯·ç¡®ä¿å®‰è£…äº†ä»¥ä¸‹ Python åº“ï¼š
```bash
pip install torch transformers peft datasets trl pandas matplotlib seaborn tqdm numpy
```

### 2. å¯åŠ¨ç¯å¢ƒæœåŠ¡å™¨
æœ¬é¡¹ç›®ä¾èµ–ä¸€ä¸ªå¤–éƒ¨è®¡ç®—ç¯å¢ƒæ¥å¤„ç† Agent çš„å·¥å…·è°ƒç”¨ã€‚è¯·ç¡®ä¿ `calculator_env` æœåŠ¡å·²å¯åŠ¨ï¼ˆä»£ç ä¸­é»˜è®¤ä¸º `http://localhost:8000`ï¼‰ï¼š
```bash
# å‡è®¾ calculator_env åœ¨ä½ çš„ python path ä¸­
python -m calculator_env.server.app
```

## ğŸš€ å·¥ä½œæµç¨‹ (Pipeline)

### Step 1: æ•°æ®ç”Ÿæˆ
ç”Ÿæˆç¬¦åˆå‰æ™¯ç†è®º ($\alpha=0.88, \lambda=2.25$) çš„åˆæˆæ•°æ®é›†ã€‚æ•°æ®åŒ…å« `<think>` æ€è€ƒè¿‡ç¨‹å’Œ `<tool>` å·¥å…·è°ƒç”¨è½¨è¿¹ã€‚
```bash
python 01_create_agent_sft_data.py
```
*   è¾“å‡º: `my_local_agent_data` (HuggingFace Dataset æ ¼å¼)

### Step 2: ç›‘ç£å¾®è°ƒ (SFT)
è®©æ¨¡å‹å­¦ä¼šä¸¤ä»¶äº‹ï¼š1. ç†è§£ç»æµå­¦æœ¯è¯­ï¼›2. å­¦ä¼šæ­£ç¡®çš„å·¥å…·è°ƒç”¨æ ¼å¼ã€‚
```bash
python 02_train_sft.py
```
*   æ¨¡å‹: `Qwen/Qwen3-0.6B` + LoRA
*   è¾“å‡º: `sft-agent-0.6b`

### Step 3: SFT æ¨¡å‹è¯„ä¼°
æµ‹è¯• SFT åçš„æ¨¡å‹åœ¨äº¤äº’å¼ç¯å¢ƒä¸­çš„è¡¨ç°ï¼Œæ£€æŸ¥å·¥å…·è°ƒç”¨æˆåŠŸç‡å’Œå†³ç­–å‡†ç¡®ç‡ã€‚
```bash
python 03_batch_test_sft.py
# æˆ–è¿›è¡Œäº¤äº’å¼å•æµ‹
python 03_test_sft_interactive.py
```
*   æ—¥å¿—: `batch_test_results.jsonl`

### Step 4: å¼ºåŒ–å­¦ä¹ å¯¹é½ (GRPO)
ä½¿ç”¨ **Group Relative Policy Optimization (GRPO)** è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹ã€‚
*   **Reward Model:** åŸºäºå†³ç­–æ˜¯å¦ç¬¦åˆæ•°å­¦æœ€ä¼˜è§£ (Outcome Reward) + æ ¼å¼æ­£ç¡®æ€§ (Format Reward)ã€‚
*   **Rollout:** åœ¨æœ¬åœ°ç¯å¢ƒä¸­é‡‡æ ·å¤šæ¡è½¨è¿¹ã€‚
```bash
python 04_train_agent_grpo.py
```

## ğŸ“Š åˆ†æä¸å¯è§†åŒ–

æœ¬é¡¹ç›®åŒ…å«ä¸°å¯Œçš„åˆ†æè„šæœ¬ï¼Œç”¨äºé‡åŒ–æ¨¡å‹çš„å¯¹é½ç¨‹åº¦ã€‚

| è„šæœ¬ | æè¿° |
| :--- | :--- |
| `06_compare_logits_utility.py` | **Logits åˆ†æ**: æ¯”è¾ƒæ¨¡å‹è¾“å‡º token (`accept`/`reject`) çš„ Logits å·®å€¼ä¸çœŸå®æ•ˆç”¨å·®å€¼ ($U_{sure} - EU_{gamble}$) çš„ç›¸å…³æ€§ã€‚ |
| `07_quantify_prompt_vs_weights.py` | **Prompt æ•ˆåº”é‡åŒ–**: åˆ†æ Prompt ä¸­è®¾å®šçš„è§’è‰²ï¼ˆå¦‚â€œé£é™©åŒæ¶â€ vs â€œèµŒå¾’â€ï¼‰å¯¹æ¨¡å‹å†³ç­–é˜ˆå€¼ (Indifference Point) çš„å®šé‡å½±å“ã€‚ |
| `08_test_sft_psychometrics.py` | **SFT å¿ƒç†æµ‹é‡**: ç»˜åˆ¶ SFT æ¨¡å‹çš„å¿ƒç†æµ‹é‡æ›²çº¿ (S-Curve)ï¼Œå¯¹æ¯”ç”±æ— å·¥å…· ("Blind") å’Œæœ‰å·¥å…· ("Agentic") çŠ¶æ€ä¸‹çš„å†³ç­–æ¦‚ç‡ã€‚ |
| `09_test_medium_model_psychometrics.py` | **åŸºåº§æ¨¡å‹åˆ†æ**: åœ¨æœªå¾®è°ƒçš„ä¸­ç­‰æ¨¡å‹ (Qwen-8B) ä¸Šè¿›è¡ŒåŒæ ·çš„å¿ƒç†æµ‹é‡åˆ†æä½œä¸ºå¯¹ç…§ç»„ã€‚ |

### ç»“æœç¤ºä¾‹ (Plots)
è¿è¡Œä¸Šè¿°è„šæœ¬å°†ç”Ÿæˆä»¥ä¸‹å›¾è¡¨ï¼š
*   `comparison_logits_utility.png`: Logits ä¸çœŸå®æ•ˆç”¨çš„çº¿æ€§å›å½’å›¾ã€‚
*   `utility_components_analysis.png`: ä¸åŒ Prompt ä¸‹æ¨¡å‹çš„ç¡®å®šæ€§æ•ˆåº” (Certainty Effect) åç§»ã€‚
*   `sft_agent_psychometrics.png`: æ¦‚ç‡æ¥å—æ›²çº¿ï¼Œå±•ç¤ºæ¨¡å‹æ˜¯å¦åœ¨ç†è®ºæ— å·®å¼‚ç‚¹ (Theoretical CE) é™„è¿‘å‘ç”Ÿç¿»è½¬ã€‚

## ğŸ“‚ ç›®å½•ç»“æ„

```text
tility-alignment-main/
â”œâ”€â”€ 01_create_agent_sft_data.py       # æ•°æ®ç”Ÿæˆ
â”œâ”€â”€ 02_train_sft.py                   # SFT è®­ç»ƒè„šæœ¬
â”œâ”€â”€ 03_batch_test_sft.py              # æ‰¹é‡æµ‹è¯•ä¸è¯„ä¼°
â”œâ”€â”€ 03_test_sft_interactive.py        # å•ä¾‹äº¤äº’æµ‹è¯•
â”œâ”€â”€ 04_train_agent_grpo.py            # GRPO å¼ºåŒ–å­¦ä¹ è®­ç»ƒ
â”œâ”€â”€ 06_compare_logits_utility.py      # Logits vs Utility åˆ†æ
â”œâ”€â”€ 07_quantify_prompt_vs_weights.py  # Prompt æ•æ„Ÿåº¦åˆ†æ
â”œâ”€â”€ 08_test_sft_psychometrics.py      # SFT æ¨¡å‹å¿ƒç†æµ‹é‡æ›²çº¿
â”œâ”€â”€ 09_test_medium_model_psychometrics.py # åŸºåº§æ¨¡å‹å¯¹ç…§åˆ†æ
â”œâ”€â”€ batch_test_results.jsonl          # æµ‹è¯•æ—¥å¿—
â””â”€â”€ my_local_agent_data/              # æœ¬åœ°æ•°æ®é›†ç›®å½•
```

## ğŸ“ å¤‡æ³¨

*   **Security:** `repomix` å¤„ç†çš„æ–‡ä»¶ä¸­ç¦ç”¨äº†å®‰å…¨æ£€æŸ¥ï¼Œè¯·ç¡®ä¿åœ¨å—æ§ç¯å¢ƒä¸­è¿è¡Œä»£ç ï¼Œå°¤å…¶æ˜¯æ¶‰åŠ `exec` æˆ–å·¥å…·è°ƒç”¨çš„éƒ¨åˆ†ã€‚
*   **Data:** å½“å‰æ•°æ®é›†åŸºäºåˆæˆç”Ÿæˆçš„äºŒå…ƒé€‰æ‹©é¢˜ (Sure thing vs Gamble)ã€‚
*   **Hardware:** 0.6B æ¨¡å‹è®­ç»ƒå¯åœ¨å•å¼ æ¶ˆè´¹çº§æ˜¾å¡ (å¦‚ RTX 3060/4090) ä¸Šå®Œæˆã€‚GRPO è®­ç»ƒå»ºè®®ä½¿ç”¨è¾ƒå¤§æ˜¾å­˜ã€‚

---
*Created by [Your Username]*