import torch
import re
from peft import AutoPeftModelForCausalLM
from transformers import AutoTokenizer

# å¼•å…¥ OpenEnv å®¢æˆ·ç«¯
from calculator_env.client import CalculatorEnv
from calculator_env.models import CalculatorAction

# ============================
# é…ç½®
# ============================
MODEL_PATH = "sft-agent-0.6b"
ENV_URL = "http://localhost:8000" # ç¡®ä¿ä½ çš„æœåŠ¡å™¨åœ¨è¿è¡Œ

# ============================
# åŠ è½½æ¨¡å‹
# ============================
print(f"ğŸ”„ Loading Model: {MODEL_PATH}...")
model = AutoPeftModelForCausalLM.from_pretrained(
    MODEL_PATH, 
    device_map="auto", 
    torch_dtype=torch.bfloat16
).eval()
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)

# ============================
# åˆå§‹åŒ–ç¯å¢ƒå®¢æˆ·ç«¯
# ============================
try:
    print(f"ğŸŒ Connecting to OpenEnv at {ENV_URL}...")
    client = CalculatorEnv(base_url=ENV_URL)
    # æµ‹è¯•ä¸€ä¸‹è¿æ¥
    client.reset()
    print("âœ… Environment Connected!")
except Exception as e:
    print(f"âŒ Environment Connection Failed: {e}")
    print("Please make sure 'python -m calculator_env.server.app' is running.")
    exit()

def run_agent_inference(p1, v1, v2, sure):
    p2 = 100 - p1
    
    # 1. åŒæ­¥é¢˜ç›®å‚æ•°ç»™ç¯å¢ƒ (è¿™æ ·å¦‚æœéœ€è¦æœåŠ¡ç«¯è®¡ç®—Rewardæ‰å‡†ç¡®ï¼Œè™½ç„¶è¿™é‡Œåªæ˜¯æµ‹è¯•)
    client.set_problem(p1, v1, v2, sure)
    client.reset()
    
    system_prompt = "You are a rational economic agent. Use the <tool> tag to perform python calculations. Finally output 'Final Decision: accept' or 'reject'."
    user_prompt = f"The prospect is: {p1}% chance of ${v1}, {p2}% chance of ${v2}. The sure outcome is: ${sure}. Do you accept?"
    
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}]
    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    
    print(f"\nğŸ¤– User: {user_prompt}")
    print("-" * 60)
    
    # æ¨¡æ‹Ÿå¤šè½®äº¤äº’ (æœ€å¤š 5 è½®)
    for turn in range(5):
        inputs = tokenizer([text], return_tensors="pt").to(model.device)
        
        with torch.no_grad():
            # ç”Ÿæˆç›´åˆ°é‡åˆ° </tool> æˆ–ç»“æŸ
            outputs = model.generate(
                **inputs, 
                max_new_tokens=200, 
                stop_strings=["</tool>"], 
                tokenizer=tokenizer,
                do_sample=False # Greedy
            )
            
        # è·å–æ–°ç”Ÿæˆçš„å†…å®¹
        new_content = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=False)
        print(f"ğŸ¤– Agent (Turn {turn}): {new_content}")
        
        text += new_content
        
        # --- æ ¸å¿ƒï¼šè°ƒç”¨ OpenEnv ---
        if "</tool>" in new_content:
            # æ„é€  Action
            action = CalculatorAction(message=new_content)
            
            # å‘é€ç»™æœåŠ¡å™¨ï¼Œè·å–ç»“æœ
            try:
                step_result = client.step(action)
                tool_output = step_result.observation.feedback
                
                print(f"ğŸŒ OpenEnv Response: {tool_output.strip()}")
                
                # å°†ç»“æœæ‹¼å›å»
                text += tool_output
                
            except Exception as e:
                print(f"âŒ OpenEnv Error: {e}")
                break
                
        elif "Final Decision" in new_content:
            print("âœ… Decision Reached.")
            break
        else:
            print("âš ï¸ Generation stopped without tool or decision.")
            break

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    # 50% 2000 vs 800 (åº”æ‹’ç»)
    run_agent_inference(50, 2000, 0, 800)